{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "from ml_trainer.tabular.models.catboost import CatBoostModel\n",
    "from ml_trainer.tabular.models.lightgbm import LightGBMModel\n",
    "from ml_trainer.tabular.models.lr import LinearRegressionModel\n",
    "from ml_trainer.tabular.models.xgboost import XGBoostModel\n",
    "from ml_trainer.tabular.trainer import Trainer\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import KFold, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_DIR = Path(\"../data\") / \"output\" / \"binary_classification\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = load_breast_cancer()[\"feature_names\"]\n",
    "raw_df = pd.concat(\n",
    "    [\n",
    "        pd.DataFrame(load_breast_cancer()[\"data\"], columns=feature_names),\n",
    "        pd.DataFrame(load_breast_cancer()[\"target\"], columns=[\"target\"]),\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "train_df, test_df = train_test_split(raw_df, test_size=0.2, random_state=8823)\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    estimators=[\n",
    "        LinearRegressionModel(feature_names=feature_names, estimator_name=\"logistic_regression\"),\n",
    "        LightGBMModel(\n",
    "            feature_names=feature_names,\n",
    "            estimator_name=\"lightgbm\",\n",
    "            params={\"objective\": \"binary\"},\n",
    "            fit_params={\n",
    "                \"callbacks\": [\n",
    "                    lgb.callback._EarlyStoppingCallback(\n",
    "                        stopping_rounds=10,\n",
    "                        verbose=True,\n",
    "                    ),\n",
    "                    lgb.callback._LogEvaluationCallback(\n",
    "                        period=10,\n",
    "                        show_stdv=True,\n",
    "                    ),\n",
    "                ]\n",
    "            },\n",
    "            use_cache=True,  # use cache for faster training\n",
    "        ),\n",
    "        CatBoostModel(\n",
    "            feature_names=feature_names,\n",
    "            estimator_name=\"catboostclassifier\",\n",
    "            params={\"loss_function\": \"Logloss\", \"early_stopping_rounds\": 10},\n",
    "            use_cache=True,\n",
    "        ),\n",
    "        XGBoostModel(\n",
    "            feature_names=feature_names,\n",
    "            estimator_name=\"xgboost\",\n",
    "            params={\n",
    "                \"objective\": \"binary:logistic\",\n",
    "                \"early_stopping_rounds\": 10,\n",
    "            },\n",
    "            use_cache=True,\n",
    "        ),\n",
    "    ],\n",
    "    out_dir=OUT_DIR,\n",
    "    split_type=KFold,\n",
    "    n_splits=4,\n",
    "    seed=8823,\n",
    "    task_type=\"binary\",\n",
    "    ensemble=True,  # mean ensemble\n",
    ")\n",
    "\n",
    "oof_preds = trainer.train_cv(X_train=train_df, y_train=train_df[\"target\"])\n",
    "trainer.scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = trainer.make_plot_feature_importances()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.make_plot_confusion_matrix(y=train_df[\"target\"], out_dir=None, palette=\"GnBu\", threshold=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_means = trainer.predict_cv(X=test_df)\n",
    "fold_means = pd.DataFrame(fold_means)  # to DataFrame from dict\n",
    "fold_means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save & Load Trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save()  # save the trainer\n",
    "trainer_new = Trainer.load(OUT_DIR / \"trainer.pkl\")  # load the trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_means_new = trainer_new.predict_cv(X=test_df)\n",
    "fold_means_new = pd.DataFrame(fold_means_new)\n",
    "fold_means_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the loaded model is the same as the original one\n",
    "all(fold_means == fold_means_new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
